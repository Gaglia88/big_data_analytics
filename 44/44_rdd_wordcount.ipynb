{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TW9lSdxBhSG"
      },
      "source": [
        "# Introduzione a Spark.\n",
        "In questo notebook verranno illustrate la basi di Spark tramite semplici esempi. Per la documentazione fare riferimento a [questa pagina](https://spark.apache.org/docs/latest/api/python/user_guide/index.html).\n",
        "\n",
        "\n",
        "Spark può essere utilizzato in Colab installando, oltre pyspark, findspark una libreria che consente di importare pyspark come una normale libreria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "028haG8lCoJG",
        "outputId": "15d667da-0f05-46fe-8298-d4827320969b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.11/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "# Installa le due librerie\n",
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurazione\n",
        "\n",
        "Vediamo le caratteristiche che ci mette a disposizione Colab"
      ],
      "metadata": {
        "id": "BJzfKZLNyLvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import psutil\n",
        "\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "\n",
        "print(f\"Memoria disponibile (dovrebbero essere 12GB): {(psutil.virtual_memory().total/2**30):.2f}\")\n",
        "print(f\"Core disponibili (dovrebbero essere 2): {cores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCScqWS_x-K5",
        "outputId": "1b6c3996-4f09-423a-c8f4-33d8df654334"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memoria disponibile (dovrebbero essere 12GB): 12.67\n",
            "Core disponibili (dovrebbero essere 2): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sulla base di questo definiamo la configurazione di Spark.\n",
        "\n",
        "Impostiamo due executor, diamo 2 GB di memoria al driver e 5 GB di memoria ad ogni executor.\n",
        "\n",
        "Di default Spark imposta 1 GB di memoria per ogni executor.\n",
        "\n",
        "Impostiamo il parallelismo a 6."
      ],
      "metadata": {
        "id": "6Y0xiB4wzRCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "\n",
        "conf = pyspark.SparkConf()\\\n",
        "    .setAppName(\"clusterSpark\")\\\n",
        "    .set(\"spark.executor.memory\", \"5g\")\\\n",
        "    .set(\"spark.driver.memory\", \"2g\")\\\n",
        "    .set(\"spark.executor.instances\", \"2\")\\\n",
        "    .set(\"spark.default.parallelism\", \"6\")"
      ],
      "metadata": {
        "id": "mldSuBUg0ePZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEnkqg4BDZfD"
      },
      "source": [
        "Dopodiché, si può inizializzare findspark e avviare Spark creando lo SparkContext.\n",
        "\n",
        "Visualizzando sc si dovrebbe avere accesso ad alcune informazioni, come la versione di Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_fvimu_eDVHw"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "sc = pyspark.SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "gLU2ORxtxCD_",
        "outputId": "9657f127-11db-429b-d627-6c6cb69c3139"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=clusterSpark>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e673169b911b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>clusterSpark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_GcJcbET4v"
      },
      "source": [
        "Possiamo vedere anche quale sia il parallelismo impostato di default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ko-gliVEBAo",
        "outputId": "af8b8351-e342-4ff3-c304-9e722459456e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "sc.defaultParallelism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQUjHJnqEbYy"
      },
      "source": [
        "Creiamo ora un array di dati random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hFeDe2rwBhSK"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "random.seed(1234)\n",
        "\n",
        "data = [random.randrange(1, 30, 1) for _ in range(1000)] #Crea un array con elementi random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e3sHI_UBhSM"
      },
      "source": [
        "<b>data</b> è un array che contiene valori interi. Si può usare il metodo <i>parallelize</i> dello SparkContext per distribuire i dati agli executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rZTVjtyVBhSN"
      },
      "outputs": [],
      "source": [
        "dataRDD = sc.parallelize(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OF4AdA8BhSO"
      },
      "source": [
        "Possiamo usare il metodo <i>cache</i> per rendere persistente l'RDD.\n",
        "Dopodiché, possiamo contare il numero di elementi contenuti all'interno dell'RDD con il metodo <i>count</i>.\n",
        "Questa è un'azione che forzerà la creazione dell'RDD che verrà quindi poi salvato nella cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4GPZdzVBhSO",
        "outputId": "08c3cba6-39a3-4e36-d741-7fa3d4cf6fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exec time 5.546101093292236\n"
          ]
        }
      ],
      "source": [
        "dataRDD.persist()\n",
        "start = time.time()\n",
        "dataRDD.count()\n",
        "end = time.time()\n",
        "print(\"Exec time \"+str((end-start)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15PkowOmBhSP"
      },
      "source": [
        "Si può vedere come la seconda volta che si esegue l'operazione, questa sarà molto più veloce, poiché l'RDD è stato salvato nella cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUW1l5tuBhSR",
        "outputId": "28ca0c5f-7dd4-42fe-d99b-c34df836a186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exec time 1.3816101551055908\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "dataRDD.count()\n",
        "end = time.time()\n",
        "print(\"Exec time \"+str((end-start)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF7vWkJDBhSS"
      },
      "source": [
        "Possiamo visualizzare alcuni elementi dell'RDD con il metodo *take*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzd97qJZBhSS",
        "outputId": "8e12ad33-3d36-40d9-e213-ffb75e374a49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[25, 15, 4, 1, 3, 26, 19, 2, 22, 23]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "dataRDD.take(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvVSHHcPBhST"
      },
      "source": [
        "Possiamo prendere i 10 elementi più grandi con <i>takeOrdered</i>. Di default takeOrdered prende gli elementi in ordine crescente, bisogna specificare manualmente l'ordine, in questo caso negando l'elemento su cui verrà poi applicato l'ordine crescente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtLKwszZBhST",
        "outputId": "116e222b-1856-4afe-ac78-9c033e807f88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[29, 29, 29, 29, 29, 29, 29, 29, 29, 29]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "dataRDD.takeOrdered(10, lambda x: -x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV-BjT_JBhSU"
      },
      "source": [
        "Possiamo usare *sum* per ottenere la somma dei valori. Anche questa è un'azione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcMg_gC3BhSU",
        "outputId": "8100203d-e786-43bf-9362-441ca81657e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15154"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "dataRDD.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uESbkNtmBhSU"
      },
      "source": [
        "La stessa operazione può essere fatta con *reduce*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbcaRo5pBhSU",
        "outputId": "e607bc2f-334c-47db-b656-4ba369da7636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15154"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataRDD.reduce(lambda x, y: x+y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEouWETSBhSU"
      },
      "source": [
        "Possiamo usare *distinct()* in combinazione con *count()* per contare il numero di elementi distinti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKbOVvPTBhSU",
        "outputId": "a0f15408-a2f1-47c6-a709-5a2917f24e57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "dataRDD.distinct().count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MUxTsdEBhSU"
      },
      "source": [
        "<h1>Word Count</h1><br />\n",
        "Vediamo ora un classico esempio di utilizzo di Spark e del calcolo distribuito: contare la frequenza dei termini in un documento.\n",
        "Innanzi tutto carichiamo alcuni dati, in particolare il documento contiene i Sonetti di Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UWg9ewzdBhSV"
      },
      "outputs": [],
      "source": [
        "import urllib.request as urllib2\n",
        "\n",
        "lines = []\n",
        "stream = urllib2.urlopen('https://dbgroup.ing.unimore.it/spark/shakespeare.txt')\n",
        "for line in stream:\n",
        "    lines.append(line.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t53OH2BBhSV"
      },
      "source": [
        "Nuovamente, possiamo parallelizzare *lines* con parallelize.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxvhVzjABhSV",
        "outputId": "0a27c540-c640-4d9d-952d-c0ab556236d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1609\\n',\n",
              " '\\n',\n",
              " 'THE SONNETS\\n',\n",
              " '\\n',\n",
              " 'by William Shakespeare\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '                     1\\n',\n",
              " '  From fairest creatures we desire increase,\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "linesRDD = sc.parallelize(lines)\n",
        "linesRDD.cache()\n",
        "linesRDD.take(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYMWX3hOBhSW"
      },
      "source": [
        "Come è possibile notare molte righe contengono caratteri speciali ('\\n') e spazi bianchi, devono essere rimossi.\n",
        "Possiamo scrivere una funzione di Python e applicarla agli elementi dell'RDD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OI98_UoeBhSW"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "  Data una stringa rimuove il carattere di fine linea\n",
        "  e gli spazi bianchi a inizio/fine.\n",
        "\"\"\"\n",
        "def clean(line):\n",
        "  return line.replace(\"\\n\", \"\").strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqNkU3lhBhSX",
        "outputId": "b4a91d8c-b899-4b0a-f6fe-2f597dda171b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1609',\n",
              " '',\n",
              " 'THE SONNETS',\n",
              " '',\n",
              " 'by William Shakespeare',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '1',\n",
              " 'From fairest creatures we desire increase,']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "linesClean = linesRDD.map(clean)\n",
        "linesClean.take(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMkPw2BsBhSX"
      },
      "source": [
        "Come si può notare vi sono linee vuote. Le possiamo rimuovere utilizzando *filter* e la funzione *len* di Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "olF1Ot-YBhSX"
      },
      "outputs": [],
      "source": [
        "linesNoBlanks = linesClean.filter(lambda x: len(x) > 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCf7FWoaBhSY"
      },
      "source": [
        "Adesso che i dati sono pronti, sarà necessario tokenizzare le linee di testo.\n",
        "\n",
        "Possiamo usare la funzione <b>tokenize</b> per ottenere i token. <br />\n",
        "<b>Attenzione:</b> splitFunction ritorna un array di token, quindi se si vuole ottenere un RDD di token sarà necessario utilizzare il metodo <b>flatMap</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Of5xpu8CBhSY"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\"\"\"\n",
        "Data una stringa ritorna i token che la compongono, suddividendola per punteggiatura o spazi bianchi\n",
        "\"\"\"\n",
        "def tokenize(str):\n",
        "  return filter(lambda token: len(token) > 0, map(lambda token: token.lower(), re.split('\\W+', str)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vHp1bHkJpVI"
      },
      "source": [
        "Possiamo vedere che se usiamo *map* non otterremo un RDD di token, ma un RDD di array di token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKrV4gdBJuUy",
        "outputId": "e30c9619-fec0-45dc-e360-55f6bb53158d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1609'],\n",
              " ['the', 'sonnets'],\n",
              " ['by', 'william', 'shakespeare'],\n",
              " ['1'],\n",
              " ['from', 'fairest', 'creatures', 'we', 'desire', 'increase']]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "linesNoBlanks.map(tokenize).map(list).take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fklq8r_J57m"
      },
      "source": [
        "Dobbiamo usare *flatMap*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06WwoHqtBhSY",
        "outputId": "f3df0e13-e480-420b-d108-cf48743a73e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1609', 'the', 'sonnets', 'by', 'william']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "tokens = linesNoBlanks.flatMap(tokenize)\n",
        "tokens.cache()\n",
        "tokens.count()\n",
        "tokens.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SA7473vBhSZ"
      },
      "source": [
        "Se ora vogliamo contare i token dobbiamo creare delle coppie (token, conteggio).\n",
        "\n",
        "Inizialmente, ogni token ha valore 1, quindi bisogna creare delle coppie (token, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xammfnh8BhSZ",
        "outputId": "6132f4c1-b0b9-45de-a083-80cfbc833952"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1609', 1), ('the', 1), ('sonnets', 1), ('by', 1), ('william', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "tokens1 = tokens.map(lambda t: (t, 1))\n",
        "tokens1.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr6rmotbKt8b"
      },
      "source": [
        "Ora possiamo raggruppare i valori e sommare gli 1.\n",
        "Si potrebbe fare con *groupByKey()* seguito da un *map*.\n",
        "Questo però **non è efficiente**, perché esegue lo shuffle di tutti gli 1, non eseguendo alcuna aggregazione locale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4C5uU8aLL8B",
        "outputId": "d78f7856-4e2b-40e5-88df-96d69296740f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "by , [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "by , 3793\n"
          ]
        }
      ],
      "source": [
        "gruppi = tokens1.groupByKey()\n",
        "v = gruppi.take(1)[0]\n",
        "print(v[0], \",\", list(v[1]))\n",
        "\n",
        "print(v[0], \",\", sum(list(v[1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZX6gYQ2BhSa"
      },
      "source": [
        "Risulta più efficace eseguire un *reduceByKey* implementando la somma. In questo modo se nella stessa partizione ci sono coppie con la stessa chiave, vengono aggregate localmente prima di fare lo shuffle.\n",
        "\n",
        "Ad esempio, se abbiamo una partizione che contiene [(by, 1), (by, 1), (by, 1), (by, 1)] invece che trasmettere tutte queste coppie, trasmette solo una coppia (by, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-7L6Jni3BhSa"
      },
      "outputs": [],
      "source": [
        "frequencies = tokens1.reduceByKey(lambda x, y: x+y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THUmsJkTBhSa"
      },
      "source": [
        "Possiamo vedere quali sono i token più frequenti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhk-A3JZBhSa",
        "outputId": "17cb10e3-e997-4b58-f3c7-5dd0b0bb4af4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 27378),\n",
              " ('and', 26084),\n",
              " ('i', 22538),\n",
              " ('to', 19771),\n",
              " ('of', 17481),\n",
              " ('a', 14725),\n",
              " ('you', 13826),\n",
              " ('my', 12490),\n",
              " ('that', 11318),\n",
              " ('in', 11112)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "frequencies.takeOrdered(10, lambda x: -x[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaBc2xRQBhSa"
      },
      "source": [
        "Come si può notare sono tutte stopwords, ossia termini di uso comune (articoli, congiunzioni, etc).\n",
        "Possiamo sfruttare l'elenco <b>english_stopwords</b> per rimuovere tutti i token che sono considerati stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FNyqGDb_BhSb"
      },
      "outputs": [],
      "source": [
        "english_stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\", \"d\", \"o\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IoSED9lBhSb"
      },
      "source": [
        "Essendo <b>english_stopwords</b> una struttura dati, per poterla utilizzare per filtrare l'RDD <b>frequencies</b>, innanzi tutto è necessario distribuirla ai worker utilizzando la funzione <i>broadcast</i>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bqL9F249BhSb"
      },
      "outputs": [],
      "source": [
        "stopwordsBroadcast = sc.broadcast(english_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB2yh4t5BhSb"
      },
      "source": [
        "Adesso possiamo <b>english_stopwords</b> per rimuovere da frequencies tutti i token che sono stopwords.\n",
        "Per verificare se un elemento è presente in una collezione di Python si può usare la sintassi: *elemento* **in** *collezione*; oppure per verificare che non sia presente *elemento* **not in** *collezione*\n",
        "\n",
        "Ricordarsi che per accedere al contenuto di una variabile in broadcast bisogna usare *variabileBroadcast.value*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "IT8R-sxlBhSc"
      },
      "outputs": [],
      "source": [
        "frequenciesNoStopwords = frequencies.filter(lambda x: x[0] not in stopwordsBroadcast.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL-j1izbBhSc"
      },
      "source": [
        "Possiamo ora ripetere ora l'operazione per visualizzare le prime 10 parole più usate da Shakespeare nei suoi Sonetti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A62gDZl0BhSc",
        "outputId": "e98b9433-9dab-4fd0-9a07-bf45bdd278bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('thou', 5549),\n",
              " ('thy', 4034),\n",
              " ('shall', 3600),\n",
              " ('thee', 3181),\n",
              " ('lord', 3094),\n",
              " ('king', 3041),\n",
              " ('good', 2834),\n",
              " ('sir', 2764),\n",
              " ('come', 2519),\n",
              " ('ll', 2409)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "frequenciesNoStopwords.takeOrdered(10, lambda x: -x[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "name": "Spark_lab_01_ex",
    "notebookId": 3776354036726934
  },
  "nbformat": 4,
  "nbformat_minor": 0
}